{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp vision.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.pipeline import *\n",
    "from local.data.core import *\n",
    "from local.data.external import *\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['Image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core vision\n",
    "> Basic image opening/processing functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/git/fastai_docs/dev/data/mnist_tiny/test/4605.png')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "fns = get_image_files(path)\n",
    "fn = fns[0]; fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Imagify(Transform):\n",
    "    \"Open an `Image` from path `fn`, show with `cmap` and `alpha`\"\n",
    "    def __init__(self, func=Image.open, **kwargs):\n",
    "        super().__init__()\n",
    "        self.func,self.kw = func,kwargs\n",
    "        \n",
    "    def encodes(self, fn): return Image.open(fn)\n",
    "    def shows(self, im, ctx=None, figsize=None):\n",
    "        return show_image(im, ax=ctx, figsize=figsize, **self.kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA30lEQVR4nGNgGHAge+v/cl3sUkrTf/79+zcazmdBklPeroyqmAnBbDmnzPBiLXYzW3/+/TtBJB3ZWAS49/evLwfDduySShv7ORjiPv+9w4fNXH4OBrNPf98HYreVQXTX37/n8cj9/bxeApucyK6/f/+iBAKSPx2dGRi+nPnAII1NZ9jfD+tsGDb8vQsXQQq+4+EvjjBw8jC8xtTHG8nAwMDA0IE1EJJvSTAwMBg9+vsTi0eT/1aLiJg9/vurCYtz4v5APHISm1sZbvz5+/fvjxkqWCUZpvz9O0MBuxQdAQDYKl1usylDbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7F0E0EB01AC8>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timg = Imagify()\n",
    "img = timg(fn)\n",
    "test_eq(img.size, (28,28))\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageConverter(Transform):\n",
    "    \"Convert `img` to `mode`\"\n",
    "    def __init__(self, mode='RGB', mask=None, is_tuple=None):\n",
    "        super().__init__(mask=mask, is_tuple=is_tuple)\n",
    "        self.mode = mode\n",
    "\n",
    "    def encodes(self, o): return o.convert(self.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ImageConverter('RGB')\n",
    "test_eq(f(img).mode, 'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def image_resize(img, size, resample=Image.BILINEAR):\n",
    "    \"Resize image to `size` using `resample\"\n",
    "    return img.resize(size, resample=resample)\n",
    "image_resize.order=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageResizer(Transform):\n",
    "    \"Resize image to `size` using `resample\"\n",
    "    def __init__(self, size, resample=Image.BILINEAR, mask=None, is_tuple=None):\n",
    "        super().__init__(mask=mask, is_tuple=is_tuple)\n",
    "        if not is_listy(size): size=(size,size)\n",
    "        self.size,self.resample = size,resample\n",
    "\n",
    "    def encodes(self, o): return image_resize(o, size=self.size, resample=self.resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA30lEQVR4nGNgGHAge+v/cl3sUkrTf/79+zcazmdBklPeroyqmAnBbDmnzPBiLXYzW3/+/TtBJB3ZWAS49/evLwfDduySShv7ORjiPv+9w4fNXH4OBrNPf98HYreVQXTX37/n8cj9/bxeApucyK6/f/+iBAKSPx2dGRi+nPnAII1NZ9jfD+tsGDb8vQsXQQq+4+EvjjBw8jC8xtTHG8nAwMDA0IE1EJJvSTAwMBg9+vsTi0eT/1aLiJg9/vurCYtz4v5APHISm1sZbvz5+/fvjxkqWCUZpvz9O0MBuxQdAQDYKl1usylDbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7F0E0EC286D8>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = ImageResizer(14)\n",
    "test_eq(f(img).size, (14,14))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def image2byte(img):\n",
    "    \"Transform image to byte tensor in `c*h*w` dim order.\"\n",
    "    res = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))\n",
    "    w,h = img.size\n",
    "    return res.view(h,w,-1).permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def unpermute_image(img):\n",
    "    \"Convert `c*h*w` dim order to `h*w*c` (or just `h*w` if 1 channel)\"\n",
    "    return img[0] if img.shape[0] == 1 else img.permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageToByteTensor(Transform):\n",
    "    \"Transform image to byte tensor in `c*h*w` dim order.\"\n",
    "    order=15\n",
    "    def encodes(self, o): return image2byte(o)\n",
    "    def decodes(self, o): return unpermute_image(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = ImageToByteTensor()\n",
    "t = tfm(img)\n",
    "test_eq(t.shape, (1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The permutation of axes needs to be reversed for display, so we define `decodes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tfm.decode(t).shape, (28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
